model:
  name: AttentionUNet
  encoder_channels: [64, 128, 256, 512]
  decoder_channels: [512, 256, 128, 64]
  attention_gates: true

data:
  img_size: 256
  augmentations:
    hflip: true
    affine:
      shift: 0.1
      scale: 0.2
      rotate: 10
    brightness_contrast: true
    gaussian_blur: true

training:
  optimizer: AdamW
  lr: 1e-4
  weight_decay: 1e-4
  batch_size: 4
  epochs: 50
  loss: BCE + Dice
  seeds: [42, 123, 2023]
  cross_validation: 5-fold

evaluation:
  metrics: [Dice, IoU, HD95, Params, Latency]

